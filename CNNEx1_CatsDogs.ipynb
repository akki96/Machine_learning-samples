{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNEx1_CatsDogs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "keyquuYMWPMa"
      },
      "source": [
        "Source:https://www.kaggle.com/c/dogs-vs-cats/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXZT2UsyIVe_",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "  -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PLy3pthUS0D2",
        "colab": {}
      },
      "source": [
        "#extract files from zip to /tmp\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLZKVtE0dSfk",
        "colab": {}
      },
      "source": [
        "#create necessary directories to split data\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "# train directories\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "\n",
        "# test directories\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H4XHh2xSfgie",
        "colab": {}
      },
      "source": [
        "#Check data shape\n",
        "print('Training (Cat) :', len(os.listdir(train_cats_dir ) ))\n",
        "print('Training (Dog) :', len(os.listdir(train_dogs_dir ) ))\n",
        "\n",
        "print('Testing (Cat) :', len(os.listdir(test_cats_dir ) ))\n",
        "print('Testing (Dog) :', len(os.listdir(test_dogs_dir ) ))\n",
        "#Expected ouput\n",
        "#1000\n",
        "#1000\n",
        "#500\n",
        "#500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b2_Q0-_5UAv-",
        "colab": {}
      },
      "source": [
        "#See the cats and dogs\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "#img_path=os.path.join(train_cats_dir, 'cat.400.jpg')\n",
        "img_path=os.path.join(train_dogs_dir, 'dog.900.jpg')\n",
        "img = mpimg.imread(img_path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ClebU9NJg99G",
        "colab": {}
      },
      "source": [
        "#Generate the data on the fly\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# reshape the image\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "#batch_size = 20 and target_size = 150x150\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PixZ2s5QbYQ3",
        "colab": {}
      },
      "source": [
        "#define the model\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    #Conv2D adds a convulation layer, 16: number of filters(https://lodev.org/cgtutor/filtering.html), (3,3) convolution \n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)), #images are 150x150 RGB(3)\n",
        "    tf.keras.layers.MaxPooling2D(2,2),                    #MaxPooling2D will reduce the dimension\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'), #another conv layer with 32 filters\n",
        "    tf.keras.layers.MaxPooling2D(2,2),                    #another pooling layer\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), #another conv layer with 64 filters \n",
        "    tf.keras.layers.MaxPooling2D(2,2),                    #anotehr pooling layers\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'),        #512 neurons\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')        #0 for cats and 1 for dogs (Binary classifier)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8DHWhFP_uhq3",
        "colab": {}
      },
      "source": [
        "#compile with RMSprop: RMS = Root Mean Squared\n",
        "from tensorflow.keras.optimizers import RMSprop \n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fb1_lgobv81m",
        "colab": {}
      },
      "source": [
        "#Fit the model with 15 epochs\n",
        "history = model.fit(train_generator,\n",
        "                              validation_data=test_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=15,\n",
        "                              validation_steps=50,\n",
        "                              verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DoWp43WxJDNT",
        "colab": {}
      },
      "source": [
        "#Let's test with random images\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded=files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  path='/content/' + fn       #Save the image to content folder\n",
        "  img=image.load_img(path, target_size=(150, 150))    #load the image\n",
        "  \n",
        "  x=image.img_to_array(img)    \n",
        "  x=np.expand_dims(x, axis=0)   \n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  classes = model.predict(images, batch_size=10)    #predict the label for the image\n",
        "  \n",
        "  print(classes[0])     #Print the label, remember it will be either one or zero\n",
        "  \n",
        "  if classes[0]>0:\n",
        "    print(fn + \" is a dog\")     #print human readable label\n",
        "    \n",
        "  else:\n",
        "    print(fn + \" is a cat\")     #print human readable label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-5tES8rXFjux",
        "colab": {}
      },
      "source": [
        "#The internal process\n",
        "import numpy as np\n",
        "import random\n",
        "from   tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "cat_img_files = [os.path.join(train_cats_dir, f) for f in ['cat.0.jpg','cat.10.jpg','cat.25.jpg','cat.40.jpg'\n",
        "                                                            ,'cat.100.jpg']]\n",
        "dog_img_files = [os.path.join(train_dogs_dir, f) for f in ['dog.0.jpg','dog.10.jpg','dog.25.jpg','dog.40.jpg'\n",
        "                                                            ,'dog.100.jpg']]\n",
        "\n",
        "img_path = random.choice(cat_img_files + dog_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  \n",
        "\n",
        "x   = img_to_array(img)                           \n",
        "x   = x.reshape((1,) + x.shape)                  \n",
        "\n",
        "x /= 255.0\n",
        "\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  \n",
        "  if len(feature_map.shape) == 4:\n",
        "    \n",
        "    n_features = feature_map.shape[-1] \n",
        "    size       = feature_map.shape[ 1]  \n",
        "    \n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    \n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='viridis' ) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}